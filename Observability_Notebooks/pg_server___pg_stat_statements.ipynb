{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pg_server_pg_stat_statement\n",
    "Shows queries from pg_stat_statements\n",
    "Cells: \n",
    "- Configure: Connect to a specfic DB\n",
    "- Current size of each table: in KB, dead rows, bloat, data size, all indexes size,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Connection\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Read from the Config file\n",
    "config = configparser.ConfigParser() \n",
    "config.read_file(open(r'../ipynb.cfg'))\n",
    "\n",
    "con_str = config.get('con_str', 'PG_AIRBASES') \n",
    "engine = sqlalchemy.create_engine(con_str)\n",
    "\n",
    "try:\n",
    "    connection = engine.connect()\n",
    "    print (\"Opened Connection\")\n",
    "except (Exception, sqlalchemy.exc.SQLAlchemyError) as error:\n",
    "    print(\"Error while connecting to PostgreSQL database:\", error)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pg_stat_statement configuration\n",
    "Notice! the notebook requires the extension pg_stat_statement. \n",
    "Show the configuration of the extension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                name setting  unit            category                                         short_desc extra_desc        context  vartype              source min_val     max_val          enumvals boot_val reset_val                         sourcefile  sourceline  pending_restart\n",
      "0             pg_stat_statements.max   10000  None  Customized Options  Sets the maximum number of statements tracked ...       None     postmaster  integer  configuration file     100  1073741823              None     5000     10000  /rdsdbdata/config/postgresql.conf        76.0            False\n",
      "1            pg_stat_statements.save      on  None  Customized Options  Save pg_stat_statements statistics across serv...       None         sighup     bool             default    None        None              None       on        on                               None         NaN            False\n",
      "2           pg_stat_statements.track     all  None  Customized Options  Selects which statements are tracked by pg_sta...       None  rds_superuser     enum  configuration file    None        None  [none, top, all]      top       all  /rdsdbdata/config/postgresql.conf        77.0            False\n",
      "3  pg_stat_statements.track_planning     off  None  Customized Options  Selects whether planning duration is tracked b...       None  rds_superuser     bool             default    None        None              None      off       off                               None         NaN            False\n",
      "4   pg_stat_statements.track_utility      on  None  Customized Options  Selects whether utility commands are tracked b...       None  rds_superuser     bool             default    None        None              None       on        on                               None         NaN            False\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "# While SQL can handle %, in python we need %% \n",
    "sql_command = \"\"\"\n",
    "select * \n",
    "from pg_settings\n",
    "where name like 'pg_stat_statements.%%'\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Execute the SQL command\n",
    "    df = pd.read_sql_query(sql_command, connection)\n",
    "    #Set the display options to show all columns without truncation\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.expand_frame_repr', False)   \n",
    "    print(df)\n",
    "except (SQLAlchemyError, ValueError) as e:\n",
    "    # Handle any errors or raised exceptions\n",
    "    raise e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 50 Queries\n",
    "Shows the top 25 queries by the total exec time. \n",
    "Notice! The measures are since the last reset of the table. Use Metis to get the hourly diff.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    total_time  total_exec_time  total_plan_time  mean_exec_time    calls                                              query\n",
      "0     27574159         27574159                0           19337     1426  SELECT * FROM postgres_air.boarding_pass WHERE...\n",
      "1     18120968         18120968                0              70   259208  SELECT calls, datname, local_blks_dirtied, loc...\n",
      "2     16285833         16285833                0            2599     6266  EXPLAIN (ANALYZE, COSTS, VERBOSE, BUFFERS, TIM...\n",
      "3      6801359          6801359                0            3479     1955  SELECT \\n        count(distinct ss.id) AS serv...\n",
      "4      5551708          5551708                0             147    37851            SELECT public.load_postgres_log_files()\n",
      "5      5048302          5048302                0             115    43987                       MOVE ALL IN \"query-cursor_1\"\n",
      "6      5000742          5000742                0           96168       52  with relevant_ids as (\\nselect\\ndistinct query...\n",
      "7      4658503          4658503                0             123    37850                   DROP TABLE postgres_logs CASCADE\n",
      "8      4302889          4302889                0            6413      671  select \\n        queryid as query_id,\\n       ...\n",
      "9      4218386          4218386                0              24   172925  SELECT psd.datname, xact_commit, xact_rollback...\n",
      "10     3503579          3503579                0              14   259208        SELECT COUNT(*) FROM pg_stat_statements($1)\n",
      "11     2884182          2884182                0            1167     2472  with relevant_ids as (\\nselect\\n distinct quer...\n",
      "12     2873475          2873475                0           31233       92  WITH lastUpdatedCTE AS (\\n    SELECT created_a...\n",
      "13     2522872          2522872                0             148    17022            SELECT public.load_postgres_log_files()\n",
      "14     2416566          2416566                0             142    17022                   DROP TABLE postgres_logs CASCADE\n",
      "15     2060257          2060257                0              62    33326            SELECT public.load_postgres_log_files()\n",
      "16     1443926          1443926                0             254     5689  select \\n        queryid as query_id,\\n       ...\n",
      "17     1392820          1392820                0             559     2492  WITH hourly_calls AS (\\n        SELECT\\n      ...\n",
      "18     1381221          1381221                0              41    33325                   DROP TABLE postgres_logs CASCADE\n",
      "19     1091767          1091767                0          545884        2  SELECT log_time, database_name, command_tag, m...\n",
      "20     1054116          1054116                0          527058        2  SELECT log_time, database_name, command_tag, m...\n",
      "21      936649           936649                0             210     4452  select *\\nfrom (select * from postgres_air.boa...\n",
      "22      924447           924447                0             151     6138  SELECT relid,\\nrelname as table_name, \\n(schem...\n",
      "23      923899           923899                0               0  2335840  SELECT  datid, datname, pid, usesysid, usename...\n",
      "24      905140           905140                0             304     2975  SELECT \\n        n1.id AS migration_id, \\n    ...\n",
      "25      768770           768770                0             797      965  SELECT relid,\\nrelname as table_name, \\n(schem...\n",
      "26      723914           723914                0             293     2473  with lagging_data as (\\n select \\nquery_id,\\nq...\n",
      "27      722242           722242                0          361121        2  SELECT log_time, database_name, command_tag, m...\n",
      "28      712671           712671                0               0  2650479  select pid, usename, client_addr, client_hostn...\n",
      "29      677877           677877                0             109     6245  SELECT\\n oid,\\n datname as database_name,\\n pg...\n",
      "30      652207           652207                0              46    14289  INSERT INTO metis.queries (query_id, query_tex...\n",
      "31      634266           634266                0             941      674  select \\n        queryid as query_id,\\n       ...\n",
      "32      609461           609461                0          304731        2  SELECT log_time, database_name, command_tag, m...\n",
      "33      603877           603877                0          301939        2  SELECT log_time, database_name, command_tag, m...\n",
      "34      538741           538741                0          269370        2  SELECT log_time, database_name, command_tag, m...\n",
      "35      535292           535292                0          535292        1  SELECT log_time, database_name, command_tag, m...\n",
      "36      520381           520381                0             160     3260  SELECT MAX(\"start_time\") FROM (SELECT \"public\"...\n",
      "37      511291           511291                0          255645        2  SELECT log_time, database_name, command_tag, m...\n",
      "38      485263           485263                0          242631        2  SELECT log_time, database_name, command_tag, m...\n",
      "39      454798           454798                0            1462      311  SELECT n.nspname AS schema, c.relname AS table...\n",
      "40      449043           449043                0          224521        2  SELECT log_time, database_name, command_tag, m...\n",
      "41      438962           438962                0             439     1001  /*\\n Query to get custom user defined types (b...\n",
      "42      431051           431051                0             434      994  /*\\n Query to get custom user defined types (b...\n",
      "43      427319           427319                0          213660        2  SELECT log_time, database_name, command_tag, m...\n",
      "44      381830           381830                0          190915        2  SELECT log_time, database_name, command_tag, m...\n",
      "45      344315           344315                0          344315        1  SELECT log_time, database_name, command_tag, m...\n",
      "46      331218           331218                0          165609        2  SELECT log_time, database_name, command_tag, m...\n",
      "47      295980           295980                0          295980        1  SELECT log_time, database_name, command_tag, m...\n",
      "48      291434           291434                0          145717        2  SELECT log_time, database_name, command_tag, m...\n",
      "49      285772           285772                0          142886        2  SELECT log_time, database_name, command_tag, m...\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "sql_command = \"\"\"\n",
    "select\n",
    "\t(total_exec_time + total_plan_time)::int as total_time,\n",
    "\ttotal_exec_time::int,\n",
    "\ttotal_plan_time::int,\n",
    "\tmean_exec_time::int,\n",
    "\tcalls,\n",
    "\tquery\n",
    "from\n",
    "\tpg_stat_statements\n",
    "order by\n",
    "\ttotal_time desc\n",
    "limit 50;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Execute the SQL command\n",
    "    df_top_tables_by_size = pd.read_sql_query(sql_command, connection)\n",
    "    print(df_top_tables_by_size)\n",
    "\n",
    "except (SQLAlchemyError, ValueError) as e:\n",
    "    # Handle any errors or raised exceptions\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
