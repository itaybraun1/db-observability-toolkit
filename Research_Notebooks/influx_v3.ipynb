{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<body>\n",
    "    <h2><span style=\"color: lightblue;\">Influx v3</span></h2>\n",
    "    <h3><strong>Desc:</strong></h3>\n",
    "    <ul>\n",
    "        <li>Write metrics to Influx Database.</li>\n",
    "        <li>Read Metrics from a bucket.</li>\n",
    "    </ul>\n",
    "    <h3>Comments:</h3>\n",
    "    <ul>\n",
    "        <li>This notebook is still in <strong>DRAFT</strong> mode.</li>\n",
    "        <li>This notebook was developed for Influx cloud v3. Do NOT use it with v2</li>\n",
    "    </ul>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Req\n",
    "1. Open an Iflux DB cloud account. Can be the free one. https://www.influxdata.com/get-influxdb/    \n",
    "2. Create a new Bucket. For ex. ```Tables_bucket```.   \n",
    "   \n",
    "The rest of the flow follows the built-in samples\n",
    "1. Open the \"Load Data\" option of \"Client\" \n",
    "2. Select \"Python\"\n",
    "3. Follow the instructions. Step \"install dependencies\" is pip install influxdb3-python, pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Token. \n",
    "Without a token, the client code can't call the API. To get a Token, log in to the cloud console, Load Data, API Tokens, Generate API Token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export INFLUXDB_TOKEN=XE9AyZ-3y-HJNyupKWiLgzVo5JMew-Y31Vq7gbakekdP66wIkBslEdnyrCc-vQ0t9MGFj449z0LvFhepVOwFfw=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Client\n",
    "Copy the code. I named the organization in Influx \"Dev\"\n",
    "\n",
    "Notice. The original code, proivded by Influx returns an error: ```[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)``` . To solve it, add the coomand ``` ssl_ca_cert=certifi.where()```. Resource: # https://stackoverflow.com/questions/69401104/influxdb-2-0-certificate-verify-failed-certificate-has-expired-ssl-c1129\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XE9AyZ-3y-HJNyupKWiLgzVo5JMew-Y31Vq7gbakekdP66wIkBslEdnyrCc-vQ0t9MGFj449z0LvFhepVOwFfw==\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from influxdb_client_3 import InfluxDBClient3, Point\n",
    "import certifi # we need it to support their certification problems. \n",
    "\n",
    "# Read from the OS or pass the parameter directly. \n",
    "token = os.environ.get(\"INFLUXDB_TOKEN\")\n",
    "token = \"XE9AyZ-3y-HJNyupKWiLgzVo5JMew-Y31Vq7gbakekdP66wIkBslEdnyrCc-vQ0t9MGFj449z0LvFhepVOwFfw==\"\n",
    "print (token)\n",
    "org = \"Dev\"\n",
    "host = \"https://us-east-1-1.aws.cloud2.influxdata.com\"\n",
    "\n",
    "client = InfluxDBClient3(host=host, token=token, org=org, ssl_ca_cert=certifi.where())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy (Insert) Data  \n",
    "The object \"Bucket\" in the UI called \"database\" in python.\n",
    "The measurement called \"Census\". Notic the ```Point``` object uses it.  \n",
    "\n",
    "\n",
    "\n",
    "In this data example, we have some important concepts:\n",
    "- **measurement**: Primary filter for the thing you are measuring. Since we are measuring the sample census of insects, our measurement is \"census\".\n",
    "- **tag**: Key-value pair to store metadata about your fields. We are storing the \"location\" of where each census is taken. Tags form part of your primary key.\n",
    "- **field**:\tKey-value pair that stores the actual data you are measuring.\tWe are storing the insect \"species\" and \"count\" as the key-value pair. Fields are not indexed and can be stored as integers, floats, strings, or booleans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete. Return to the InfluxDB UI.\n"
     ]
    }
   ],
   "source": [
    "database=\"Tables_Bucket\"\n",
    "\n",
    "data = {\n",
    "  \"point1\": {\n",
    "    \"location\": \"Klamath\",\n",
    "    \"species\": \"bees\",\n",
    "    \"count\": 25,\n",
    "  },\n",
    "  \"point2\": {\n",
    "    \"location\": \"Portland\",\n",
    "    \"species\": \"ants\",\n",
    "    \"count\": 32,\n",
    "  },\n",
    "  \"point3\": {\n",
    "    \"location\": \"Klamath\",\n",
    "    \"species\": \"bees\",\n",
    "    \"count\": 28,\n",
    "  },\n",
    "  \"point4\": {\n",
    "    \"location\": \"Portland\",\n",
    "    \"species\": \"ants\",\n",
    "    \"count\": 36,\n",
    "  },\n",
    "  \"point5\": {\n",
    "    \"location\": \"Klamath\",\n",
    "    \"species\": \"bees\",\n",
    "    \"count\": 27,\n",
    "  },\n",
    "  \"point6\": {\n",
    "    \"location\": \"Portland\",\n",
    "    \"species\": \"ants\",\n",
    "    \"count\": 43,\n",
    "  },\n",
    "}\n",
    "\n",
    "for key in data:\n",
    "  point = (\n",
    "    Point(\"census\")\n",
    "    .tag(\"location\", data[key][\"location\"])\n",
    "    .field(data[key][\"species\"], data[key][\"count\"])\n",
    "  )\n",
    "  client.write(database=database, record=point)\n",
    "  time.sleep(1) # separate points by 1 second\n",
    "\n",
    "print(\"Complete. Return to the InfluxDB UI.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute a Simple Query\n",
    "v3 supports SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ants', 'bees', 'location', 'time'], dtype='object')\n",
      "    ants  bees  location                          time\n",
      "0    NaN  23.0   Klamath 2023-09-17 15:50:32.816591687\n",
      "6   30.0   NaN  Portland 2023-09-17 15:50:34.151910341\n",
      "1    NaN  28.0   Klamath 2023-09-17 15:50:35.335547781\n",
      "7   32.0   NaN  Portland 2023-09-17 15:50:36.595085749\n",
      "2    NaN  29.0   Klamath 2023-09-17 15:50:37.815063826\n",
      "8   40.0   NaN  Portland 2023-09-17 15:50:38.975112553\n",
      "3    NaN  23.0   Klamath 2023-09-17 19:48:09.639242780\n",
      "9   30.0   NaN  Portland 2023-09-17 19:48:10.808677735\n",
      "4    NaN  28.0   Klamath 2023-09-17 19:48:12.002052431\n",
      "10  32.0   NaN  Portland 2023-09-17 19:48:13.156166514\n",
      "5    NaN  29.0   Klamath 2023-09-17 19:48:14.321562173\n",
      "11  40.0   NaN  Portland 2023-09-17 19:48:15.539494349\n",
      "12   NaN  25.0   Klamath 2023-09-23 20:35:34.764041824\n",
      "15  32.0   NaN  Portland 2023-09-23 20:35:36.123439256\n",
      "13   NaN  28.0   Klamath 2023-09-23 20:35:37.362155251\n",
      "16  36.0   NaN  Portland 2023-09-23 20:35:38.603744675\n",
      "14   NaN  27.0   Klamath 2023-09-23 20:35:39.766943693\n",
      "17  43.0   NaN  Portland 2023-09-23 20:35:40.936207328\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT *\n",
    "FROM 'census'\n",
    "WHERE time >= now() - interval '168 hours'\n",
    "AND ('bees' IS NOT NULL OR 'ants' IS NOT NULL)\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "table = client.query(query=query, database=\"Tables_Bucket\", language='sql') \n",
    "\n",
    "# Convert to dataframe\n",
    "df = table.to_pandas().sort_values(by=\"time\")\n",
    "column_names = df.columns\n",
    "print(column_names)\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advance Query\n",
    "Sep 17 - doesn't work. Not sure why as it is copy paste from the demo. \n",
    "I suspect the fact I had to use \"sql\" as a language to make it work, and not \"influxql\" is the root cause. The documentation says using ```import influxdb_client_3 as InfluxDBClient3``` with influxql but it doesn't work.    \n",
    "\n",
    "Trying to implement ```GROUP BY``` using: https://docs.influxdata.com/influxdb/v1/query_language/explore-data/#the-group-by-clause "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   location              MAX(census.time)  AVG(census.ants)\n",
      "0  Portland 2023-09-23 20:35:40.936207328              37.0\n"
     ]
    }
   ],
   "source": [
    "## Execute Aggregate Queries. The first one works\n",
    "query = \"\"\"\n",
    "SELECT  location, max(time), avg(census.ants)\n",
    "FROM \"census\"\n",
    "WHERE time >= now() - interval '1 hour'\n",
    "AND (ants IS NOT NULL)\n",
    "GROUP BY location\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Execute the query\n",
    "table = client.query(query=query, database=\"Tables_Bucket\", language='sql') \n",
    "\n",
    "# Convert to dataframe\n",
    "df = table.to_pandas()#.sort_values(by='time')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always use a good olf Flux to run a GROUP BY query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "influx query \\\n",
    "'from(bucket: \"Tables_Bucket\")\n",
    "  |> range(start: -1h)\n",
    "  |> filter(fn: (r) => r._measurement == \"airSensors\" and r._field == \"humidity\")\n",
    "  |> aggregateWindow(every: 5m, fn: max)'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete a bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# InfluxDB API endpoint\n",
    "base_url = \"http://localhost:8086\"\n",
    "org = \"your_organization\"  # Replace with your organization name\n",
    "bucket = \"your_bucket\"      # Replace with the name of the bucket you want to delete\n",
    "\n",
    "# Authentication token (if required)\n",
    "token = \"your_authentication_token\"  # Replace with your authentication token, if needed\n",
    "\n",
    "# Construct the URL for deleting the bucket\n",
    "url = f\"{base_url}/api/v2/buckets/{org}/{bucket}\"\n",
    "\n",
    "# Headers for the request (include the authentication token if required)\n",
    "headers = {\n",
    "    \"Authorization\": f\"Token {token}\" if token else \"\",\n",
    "}\n",
    "\n",
    "# Send the DELETE request to delete the bucket\n",
    "response = requests.delete(url, headers=headers)\n",
    "\n",
    "# Check the response status code\n",
    "if response.status_code == 204:\n",
    "    print(f\"Bucket '{bucket}' deleted successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to delete bucket '{bucket}'. Status code: {response.status_code}\")\n",
    "    print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
