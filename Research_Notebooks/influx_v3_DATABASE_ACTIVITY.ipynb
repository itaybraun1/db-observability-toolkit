{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<body>\n",
    "    <h2><span style=\"color: lightblue;\">Influx v3</span></h2>\n",
    "    <h3><strong>Desc:</strong></h3>\n",
    "    <ul>\n",
    "        <li>Write metrics to Influx Database.</li>\n",
    "        <li>Read Metrics from a bucket.</li>\n",
    "    </ul>\n",
    "    <h3>Comments:</h3>\n",
    "    <ul>\n",
    "        <li>This notebook is still in <strong>DRAFT</strong> mode.</li>\n",
    "        <li>This notebook was developed for Influx cloud v3. Do NOT use it with v2</li>\n",
    "    </ul>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Req\n",
    "1. Open an Iflux DB cloud account. Can be the free one. https://www.influxdata.com/get-influxdb/    \n",
    "2. Create a new Bucket. For ex. ```Tables_bucket```.   \n",
    "3. To learn about the InfluxDB terminology, rad here: https://docs.influxdata.com/influxdb/v2/get-started/ \n",
    "   \n",
    "The rest of the flow follows the built-in samples\n",
    "1. Open the \"Load Data\" option of \"Client\" \n",
    "2. Select \"Python\"\n",
    "3. Follow the instructions. Step \"install dependencies\" is pip install influxdb3-python, pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Token. \n",
    "Without a token, the client code can't call the API. To get a Token, log in to the cloud console, Load Data, API Tokens, Generate API Token. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Client\n",
    "Copy the code. I named the organization in Influx \"Dev\"\n",
    "\n",
    "Notice. The original code, proivded by Influx returns an error: ```[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)``` . To solve it, add the coomand ``` ssl_ca_cert=certifi.where()```. Resource: # https://stackoverflow.com/questions/69401104/influxdb-2-0-certificate-verify-failed-certificate-has-expired-ssl-c1129\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from influxdb_client_3 import InfluxDBClient3, Point\n",
    "import certifi # we need it to support their certification problems. \n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# token = \"ylThfbJSW4MDfbcEIyNQsS2vnHOBjz-Uanc0KgHAZIcpBSRPc1WaPRwVKmdNzPj8H-HNQyEaN32dqrC10zjVWg==\"\n",
    "token = \"PjObG70ZggAu78U5hN9awHq5pOk6GOtAsu7Fp4JROzdHmllRCMrlQh0r9owylgKR0A_Ki7-EYgzz03TNad0tqw==\"\n",
    "org = \"Metis-v3\"\n",
    "host = \"https://eu-central-1-1.aws.cloud2.influxdata.com\"\n",
    "bucket = \"test\"\n",
    "\n",
    "try: \n",
    "    client = InfluxDBClient3(host=host, token=token, org=org, ssl_ca_cert=certifi.where())\n",
    "except ExceptionType as e:\n",
    "    print (str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute a Simple Query - SQL \n",
    "v3 supports SQL. v2 couldn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Flight returned invalid argument error, with message: bucket \"Tables_Bucket\" not found. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.123.149.45:443 {created_time:\"2023-10-22T15:03:14.792118+03:00\", grpc_status:3, grpc_message:\"bucket \\\"Tables_Bucket\\\" not found\"}. Client context: IOError: Server never sent a data message. Detail: Internal",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_DATABASE_ACTIVITY.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_DATABASE_ACTIVITY.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mSELECT *\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_DATABASE_ACTIVITY.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mFROM \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcensus\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_DATABASE_ACTIVITY.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mWHERE time >= now() - interval \u001b[39m\u001b[39m'\u001b[39m\u001b[39m168 hours\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_DATABASE_ACTIVITY.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mAND (\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbees\u001b[39m\u001b[39m'\u001b[39m\u001b[39m IS NOT NULL OR \u001b[39m\u001b[39m'\u001b[39m\u001b[39mants\u001b[39m\u001b[39m'\u001b[39m\u001b[39m IS NOT NULL)\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_DATABASE_ACTIVITY.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Execute the query\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_DATABASE_ACTIVITY.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m table \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mquery(query\u001b[39m=\u001b[39;49mquery, database\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTables_Bucket\u001b[39;49m\u001b[39m\"\u001b[39;49m, language\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msql\u001b[39;49m\u001b[39m'\u001b[39;49m) \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_DATABASE_ACTIVITY.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Convert to dataframe\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_DATABASE_ACTIVITY.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df \u001b[39m=\u001b[39m table\u001b[39m.\u001b[39mto_pandas()\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/influxdb_client_3/__init__.py:196\u001b[0m, in \u001b[0;36mInfluxDBClient3.query\u001b[0;34m(self, query, language, mode, database, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[39mreturn\u001b[39;00m mode_func() \u001b[39mif\u001b[39;00m callable(mode_func) \u001b[39melse\u001b[39;00m mode_func\n\u001b[1;32m    195\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/influxdb_client_3/__init__.py:184\u001b[0m, in \u001b[0;36mInfluxDBClient3.query\u001b[0;34m(self, query, language, mode, database, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m ticket_data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mdatabase\u001b[39m\u001b[39m\"\u001b[39m: database, \u001b[39m\"\u001b[39m\u001b[39msql_query\u001b[39m\u001b[39m\"\u001b[39m: query, \u001b[39m\"\u001b[39m\u001b[39mquery_type\u001b[39m\u001b[39m\"\u001b[39m: language}\n\u001b[1;32m    183\u001b[0m ticket \u001b[39m=\u001b[39m Ticket(json\u001b[39m.\u001b[39mdumps(ticket_data)\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m--> 184\u001b[0m flight_reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flight_client\u001b[39m.\u001b[39;49mdo_get(ticket, _options)\n\u001b[1;32m    186\u001b[0m mode_func \u001b[39m=\u001b[39m {\n\u001b[1;32m    187\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m: flight_reader\u001b[39m.\u001b[39mread_all,\n\u001b[1;32m    188\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpandas\u001b[39m\u001b[39m\"\u001b[39m: flight_reader\u001b[39m.\u001b[39mread_pandas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mschema\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m: flight_reader\u001b[39m.\u001b[39mschema\n\u001b[1;32m    192\u001b[0m }\u001b[39m.\u001b[39mget(mode, flight_reader\u001b[39m.\u001b[39mread_all)\n\u001b[1;32m    194\u001b[0m \u001b[39mreturn\u001b[39;00m mode_func() \u001b[39mif\u001b[39;00m callable(mode_func) \u001b[39melse\u001b[39;00m mode_func\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyarrow/_flight.pyx:1539\u001b[0m, in \u001b[0;36mpyarrow._flight.FlightClient.do_get\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyarrow/_flight.pyx:81\u001b[0m, in \u001b[0;36mpyarrow._flight.check_flight_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Flight returned invalid argument error, with message: bucket \"Tables_Bucket\" not found. gRPC client debug context: UNKNOWN:Error received from peer ipv4:3.123.149.45:443 {created_time:\"2023-10-22T15:03:14.792118+03:00\", grpc_status:3, grpc_message:\"bucket \\\"Tables_Bucket\\\" not found\"}. Client context: IOError: Server never sent a data message. Detail: Internal"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT *\n",
    "FROM 'census'\n",
    "WHERE time >= now() - interval '168 hours'\n",
    "AND ('bees' IS NOT NULL OR 'ants' IS NOT NULL)\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "table = client.query(query=query, database=\"Tables_Bucket\", language='sql') \n",
    "\n",
    "# Convert to dataframe\n",
    "df = table.to_pandas().sort_values(by=\"time\")\n",
    "column_names = df.columns\n",
    "print(column_names)\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the data - Group by time ranges\n",
    "You can always use a good olf Flux to run a GROUP BY query. Group the data every 5 min. \n",
    "It the query doesn't return any data, that means that no data was inserted to this Influx Bucket. See one of the cells above how to insert data.   \n",
    "\n",
    "- Example 1 - running using the Influx CLI ( ```brew install influxdb-cli```). Apparently it still works with Flux. \n",
    "- Exampel 2 - Running using Python. It can't use Flux anymore. Only InfluQL ( https://docs.influxdata.com/influxdb/v1/query_language/, supported languages now are only SQL or InfluxQL: https://docs.influxdata.com/influxdb/cloud-dedicated/reference/client-libraries/v3/python/#functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on V3 - real world data\n",
    "Step 1: A single Query ID, last 14 days, group hourly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    iox::measurement                time  \\\n",
      "0      QUERY_DETAILS 2023-10-05 00:00:00   \n",
      "1      QUERY_DETAILS 2023-10-05 01:00:00   \n",
      "2      QUERY_DETAILS 2023-10-05 02:00:00   \n",
      "3      QUERY_DETAILS 2023-10-05 03:00:00   \n",
      "4      QUERY_DETAILS 2023-10-05 04:00:00   \n",
      "..               ...                 ...   \n",
      "416    QUERY_DETAILS 2023-10-22 08:00:00   \n",
      "417    QUERY_DETAILS 2023-10-22 09:00:00   \n",
      "418    QUERY_DETAILS 2023-10-22 10:00:00   \n",
      "419    QUERY_DETAILS 2023-10-22 11:00:00   \n",
      "420    QUERY_DETAILS 2023-10-22 12:00:00   \n",
      "\n",
      "                                       apiKey           db  \\\n",
      "0    mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm  platform-v2   \n",
      "1    mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm  platform-v2   \n",
      "2    mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm  platform-v2   \n",
      "3    mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm  platform-v2   \n",
      "4    mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm  platform-v2   \n",
      "..                                        ...          ...   \n",
      "416  mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm  platform-v2   \n",
      "417  mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm  platform-v2   \n",
      "418  mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm  platform-v2   \n",
      "419  mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm  platform-v2   \n",
      "420  mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm  platform-v2   \n",
      "\n",
      "                query_id        max  \n",
      "0    1147616880456321454  1056724.0  \n",
      "1    1147616880456321454  1057421.0  \n",
      "2    1147616880456321454  1058026.0  \n",
      "3    1147616880456321454  1058804.0  \n",
      "4    1147616880456321454  1059566.0  \n",
      "..                   ...        ...  \n",
      "416  1147616880456321454  1364483.0  \n",
      "417  1147616880456321454  1365374.0  \n",
      "418  1147616880456321454  1366340.0  \n",
      "419  1147616880456321454  1367244.0  \n",
      "420  1147616880456321454  1367635.0  \n",
      "\n",
      "[421 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# InfluxQL Query (NOT Flux)\n",
    "# The last 14 days of a specific query ID, group by hour. \n",
    "\n",
    "### THIS QUERY DOESN'T WORK - the query should show the hourly diff of every hour. It shows 0.\n",
    "### I have no idea what fill(NULL) dows but no impact. \n",
    "query = \"\"\"\n",
    "SELECT time,\n",
    "    apiKey,\n",
    "    db,\n",
    "    query_id, \n",
    "    max(calls)\n",
    "   -- DERIVATIVE(max(calls))\n",
    "FROM QUERY_DETAILS\n",
    "WHERE time >= '2023-10-5T00:00:00Z'\n",
    "AND apiKey = 'mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm'\n",
    "-- AND host = 'database-2.cofhrj7zmyn4.eu-central-1.rds.amazonaws.com'\n",
    "-- AND db = 'platform-v2'\n",
    "\n",
    "GROUP BY time(60m)  fill(null)\n",
    "\"\"\"\n",
    "table = client.query(query=query, database=bucket, mode =\"all\", language=\"influxql\")\n",
    "dataframe = table.to_pandas() # This one automatically eliminitaes the NULL values. Not good. \n",
    "print (dataframe)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InfluxQL queries for the widgets of the Database Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iox::measurement</th>\n",
       "      <th>time</th>\n",
       "      <th>apiKey</th>\n",
       "      <th>host</th>\n",
       "      <th>db</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUERY_DETAILS</td>\n",
       "      <td>2023-10-15 00:00:00</td>\n",
       "      <td>mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm</td>\n",
       "      <td>database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...</td>\n",
       "      <td>airbases</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUERY_DETAILS</td>\n",
       "      <td>2023-10-15 01:00:00</td>\n",
       "      <td>mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm</td>\n",
       "      <td>database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...</td>\n",
       "      <td>airbases</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QUERY_DETAILS</td>\n",
       "      <td>2023-10-15 02:00:00</td>\n",
       "      <td>mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm</td>\n",
       "      <td>database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...</td>\n",
       "      <td>airbases</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUERY_DETAILS</td>\n",
       "      <td>2023-10-15 03:00:00</td>\n",
       "      <td>mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm</td>\n",
       "      <td>database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...</td>\n",
       "      <td>airbases</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QUERY_DETAILS</td>\n",
       "      <td>2023-10-15 04:00:00</td>\n",
       "      <td>mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm</td>\n",
       "      <td>database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...</td>\n",
       "      <td>airbases</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>QUERY_DETAILS</td>\n",
       "      <td>2023-10-22 08:00:00</td>\n",
       "      <td>mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm</td>\n",
       "      <td>database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...</td>\n",
       "      <td>airbases</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>QUERY_DETAILS</td>\n",
       "      <td>2023-10-22 09:00:00</td>\n",
       "      <td>mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm</td>\n",
       "      <td>database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...</td>\n",
       "      <td>airbases</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>QUERY_DETAILS</td>\n",
       "      <td>2023-10-22 10:00:00</td>\n",
       "      <td>mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm</td>\n",
       "      <td>database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...</td>\n",
       "      <td>airbases</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>QUERY_DETAILS</td>\n",
       "      <td>2023-10-22 11:00:00</td>\n",
       "      <td>mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm</td>\n",
       "      <td>database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...</td>\n",
       "      <td>airbases</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>QUERY_DETAILS</td>\n",
       "      <td>2023-10-22 12:00:00</td>\n",
       "      <td>mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm</td>\n",
       "      <td>database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...</td>\n",
       "      <td>airbases</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    iox::measurement                time  \\\n",
       "0      QUERY_DETAILS 2023-10-15 00:00:00   \n",
       "1      QUERY_DETAILS 2023-10-15 01:00:00   \n",
       "2      QUERY_DETAILS 2023-10-15 02:00:00   \n",
       "3      QUERY_DETAILS 2023-10-15 03:00:00   \n",
       "4      QUERY_DETAILS 2023-10-15 04:00:00   \n",
       "..               ...                 ...   \n",
       "176    QUERY_DETAILS 2023-10-22 08:00:00   \n",
       "177    QUERY_DETAILS 2023-10-22 09:00:00   \n",
       "178    QUERY_DETAILS 2023-10-22 10:00:00   \n",
       "179    QUERY_DETAILS 2023-10-22 11:00:00   \n",
       "180    QUERY_DETAILS 2023-10-22 12:00:00   \n",
       "\n",
       "                                       apiKey  \\\n",
       "0    mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm   \n",
       "1    mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm   \n",
       "2    mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm   \n",
       "3    mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm   \n",
       "4    mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm   \n",
       "..                                        ...   \n",
       "176  mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm   \n",
       "177  mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm   \n",
       "178  mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm   \n",
       "179  mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm   \n",
       "180  mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm   \n",
       "\n",
       "                                                  host        db  max  \n",
       "0    database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...  airbases  0.0  \n",
       "1    database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...  airbases  0.0  \n",
       "2    database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...  airbases  0.0  \n",
       "3    database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...  airbases  0.0  \n",
       "4    database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...  airbases  0.0  \n",
       "..                                                 ...       ...  ...  \n",
       "176  database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...  airbases  0.0  \n",
       "177  database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...  airbases  0.0  \n",
       "178  database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...  airbases  0.0  \n",
       "179  database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...  airbases  0.0  \n",
       "180  database-2.cofhrj7zmyn4.eu-central-1.rds.amazo...  airbases  0.0  \n",
       "\n",
       "[181 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The last 14 days of a specific query ID, group by hour. \n",
    "\n",
    "query_first_100_rows = \"\"\"\n",
    "SELECT time,\n",
    "    apiKey,\n",
    "    db,\n",
    "    host,\n",
    "    value\n",
    "FROM ROWS_FETCHED\n",
    "WHERE time >= '2023-10-15T00:00:00Z'\n",
    "AND apiKey = 'mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm'\n",
    "AND host = 'database-2.cofhrj7zmyn4.eu-central-1.rds.amazonaws.com'\n",
    "AND db = 'platform-v2'\n",
    "LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "query_rows_read = \"\"\"\n",
    "SELECT time,\n",
    "    apiKey,\n",
    "    host,\n",
    "    db,\n",
    "    max(value)\n",
    "FROM QUERY_DETAILS\n",
    "WHERE time >= '2023-10-15T00:00:00Z'\n",
    "AND apiKey = 'mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm'\n",
    "--AND host = 'database-2.cofhrj7zmyn4.eu-central-1.rds.amazonaws.com'\n",
    "-- AND db = 'platform-v2'\n",
    "GROUP BY time(60m)  fill(null)\n",
    "\"\"\"\n",
    "# table = client.query(query=query_first_100_rows, database=bucket, mode =\"all\", language=\"influxql\")\n",
    "table = client.query(query=query_rows_read, database=bucket, mode =\"all\", language=\"influxql\")\n",
    "dataframe = table.to_pandas() # This one automatically eliminitaes the NULL values. Not good. \n",
    "dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 8.002975 seconds\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'query_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'query_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_Queries.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_Queries.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data_dict)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_Queries.ipynb#X14sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m df\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_Queries.ipynb#X14sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m distinct_values_count \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mquery_id\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mnunique()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_Queries.ipynb#X14sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of distinct values in \u001b[39m\u001b[39m'\u001b[39m\u001b[39mquery_id\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mdistinct_values_count\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_Queries.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Close the client connection\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/itaybraun/Documents/GitHub/db-observability-toolkit/Research_Notebooks/influx_v3_Queries.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# client.close()\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'query_id'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    " ############################################\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "  SUM(\"calls\") AS sum_calls\n",
    "FROM\n",
    "  \"test\".\"autogen\".\"QUERY_DETAILS\"\n",
    "WHERE\n",
    "  time >= now() - 24h\n",
    "  AND apiKey = 'mj1Vde9QC664608cJ24CV3Zf2Y9tdgzt20P8quOm'\n",
    "  AND \"host\" = 'database-2.cofhrj7zmyn4.eu-central-1.rds.amazonaws.com'\n",
    "  AND \"db\" = 'platform-v2'\n",
    " \n",
    "GROUP BY\n",
    "  time(1h),  \"query_id\"\n",
    "\n",
    "\"\"\"\n",
    " # -- AND query_id = '998035682853375308'\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "table = client.query(query=query, database=bucket, mode =\"all\", language=\"influxql\")\n",
    "end_time = datetime.datetime.now()\n",
    "time_difference = end_time - start_time\n",
    "print(f\"Time elapsed: {time_difference.total_seconds()} seconds\")\n",
    "\n",
    "dataframe = table.to_pandas() # This one automatically eliminitaes the NULL values. Not good. \n",
    "print\n",
    "\n",
    "data_dict = {\n",
    "    \"Measurement\": table[0],\n",
    "    \"Time\": table[1],\n",
    "    \"apiKey\":table[2],\n",
    "    \"host\":table[3],\n",
    "    # \"db\":table[4],\n",
    "    # \"query_id\":table[5],\n",
    "    # \"Max\": table[6]\n",
    "}\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "df\n",
    "\n",
    "distinct_values_count = df['query_id'].nunique()\n",
    "print(f\"Number of distinct values in 'query_id': {distinct_values_count}\")\n",
    "\n",
    "# Close the client connection\n",
    "# client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read using InfluxQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "influx query \\\n",
    "'from(bucket: \"Tables_Bucket\")\n",
    "  |> range(start: -14d, stop: -12d)\n",
    "  |> filter(fn: (r) => r._measurement == \"m\" and r._field == \"calls\" and r.query_id == \"qry1\")\n",
    "  |> aggregateWindow(every: 60m, fn: max)\n",
    "  |> difference(nonNegative: true)\n",
    "  |> drop(columns: [\"_start\", \"_stop\", \"_measurement\"])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "iox::measurement: string not null\n",
      "time: timestamp[ns]\n",
      "difference_calls: double\n",
      "----\n",
      "iox::measurement: []\n",
      "time: []\n",
      "difference_calls: []\n"
     ]
    }
   ],
   "source": [
    "# Define your InfluxDB connection details\n",
    "#url = \"http://localhost:8086\"\n",
    "#token = \"your_influxdb_token\"\n",
    "#org = \"your_organization\"\n",
    "bucket = \"Tables_Bucket\"\n",
    "\n",
    "# SQL Query (NOT Flux)\n",
    "query = \"\"\"\n",
    "SELECT query_id, max(calls)\n",
    "FROM \"queries\"\n",
    "WHERE time >= '2023-10-10T00:00:00Z'\n",
    "GROUP by query_id, time(60m)\n",
    "\"\"\"\n",
    "\n",
    "## Query_2 Doesn't work\n",
    "query_2 = \"\"\"\n",
    "SELECT derivative(max(\"calls\"), 5m) AS \"difference_calls\"\n",
    "FROM \"queries\"\n",
    "WHERE time >= -14d AND time < -12d AND query_id = 'qry1'\n",
    "GROUP BY time(60m) fill(null)\n",
    "\"\"\"\n",
    "\n",
    "token = os.environ.get(\"INFLUXDB_TOKEN\")\n",
    "token = \"XE9AyZ-3y-HJNyupKWiLgzVo5JMew-Y31Vq7gbakekdP66wIkBslEdnyrCc-vQ0t9MGFj449z0LvFhepVOwFfw==\"\n",
    "org = \"Dev\"\n",
    "host = \"https://us-east-1-1.aws.cloud2.influxdata.com\"\n",
    "\n",
    "client = InfluxDBClient3(host=host, token=token, org=org, ssl_ca_cert=certifi.where())\n",
    "# You can bring only the schema to help troubleshooting\n",
    "# schema = client.query(query=query, database=\"Tables_Bucket\", mode=\"schema\", language=\"influxql\")\n",
    "# print(schema)\n",
    "\n",
    "table = client.query(query=query_2, database=\"Tables_Bucket\", mode =\"all\", language=\"influxql\")\n",
    "dataframe = table.to_pandas() # This one automatically eliminitaes the NULL values. Not good. \n",
    "print (table)\n",
    "\n",
    "\n",
    "# Close the client connection\n",
    "# client.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
