{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "\n",
    "<body>\n",
    "    <h2><span style=\"color: lightblue;\">Influx v3 - Insert High Cardinality Data</span></h2>\n",
    "    <h3><strong>Desc:</strong></h3>\n",
    "    <ul>\n",
    "        <li>Generate dummy data using Python Pandas.</li>\n",
    "        <li>Convert the data to CSV.</li>\n",
    "        <li>Insert the CSV to Influx.</li>\n",
    "    </ul>\n",
    "    <h3>Comments:</h3>\n",
    "    <ul>\n",
    "        <li>This notebook is still in <strong>DRAFT</strong> mode.</li>\n",
    "        <li>This notebook was developed for Influx cloud v3. Do NOT use it with v2</li>\n",
    "    </ul>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to Influx v3 \n",
    "import os, time\n",
    "from influxdb_client_3 import InfluxDBClient3, Point\n",
    "import certifi # we need it to support their certification problems. \n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "token = \"PjObG70ZggAu78U5hN9awHq5pOk6GOtAsu7Fp4JROzdHmllRCMrlQh0r9owylgKR0A_Ki7-EYgzz03TNad0tqw==\"\n",
    "org = \"Metis-v3\"\n",
    "host = \"https://eu-central-1-1.aws.cloud2.influxdata.com\"\n",
    "bucket = \"test\"\n",
    "\n",
    "try: \n",
    "    client = InfluxDBClient3(host=host, token=token, org=org, ssl_ca_cert=certifi.where())\n",
    "except ExceptionType as e:\n",
    "    print (str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <h3><span style=\"color: lightblue;\">View the Exisintg data</span></h3>\n",
    "    <ul>\n",
    "        <li>The size of the Measurement (num of rows)</li>\n",
    "        <li>Numebr of items in each series.</li>\n",
    "    </ul>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  iox::measurement       time  count_calls  count_rows  count_total_exec_time  \\\n",
      "0    QUERY_DETAILS 1970-01-01     32768959    32768959               32768959   \n",
      "\n",
      "   count_value  \n",
      "0     32768959  \n",
      "       iox::measurement                    time      apiKey             db  \\\n",
      "0   DS_INDEXES_ACTIVITY 2023-10-24 12:34:43.751  newvertest       airbases   \n",
      "1   DS_INDEXES_ACTIVITY 2023-10-24 12:34:43.751  newvertest       airbases   \n",
      "2   DS_INDEXES_ACTIVITY 2023-10-24 12:34:43.751  newvertest       airbases   \n",
      "3   DS_INDEXES_ACTIVITY 2023-10-24 12:34:43.751  newvertest       airbases   \n",
      "4   DS_INDEXES_ACTIVITY 2023-10-24 12:34:43.751  newvertest       airbases   \n",
      "..                  ...                     ...         ...            ...   \n",
      "95  DS_INDEXES_ACTIVITY 2023-10-24 12:34:43.751  newvertest  airbases-demo   \n",
      "96  DS_INDEXES_ACTIVITY 2023-10-24 12:34:43.751  newvertest  airbases-demo   \n",
      "97  DS_INDEXES_ACTIVITY 2023-10-24 12:34:43.751  newvertest  airbases-demo   \n",
      "98  DS_INDEXES_ACTIVITY 2023-10-24 12:34:43.751  newvertest  airbases-demo   \n",
      "99  DS_INDEXES_ACTIVITY 2023-10-24 12:34:43.751  newvertest  airbases-demo   \n",
      "\n",
      "                                deviceId             index_name  \\\n",
      "0   0809e277-0af2-46df-b5ff-de10995b95d5           account_pkey   \n",
      "1   0809e277-0af2-46df-b5ff-de10995b95d5          accounts_pkey   \n",
      "2   0809e277-0af2-46df-b5ff-de10995b95d5          aircraft_pkey   \n",
      "3   0809e277-0af2-46df-b5ff-de10995b95d5           airport_pkey   \n",
      "4   0809e277-0af2-46df-b5ff-de10995b95d5     boarding_pass_pkey   \n",
      "..                                   ...                    ...   \n",
      "95  0809e277-0af2-46df-b5ff-de10995b95d5   idx_scheduled_flight   \n",
      "96  0809e277-0af2-46df-b5ff-de10995b95d5       index_stats_pkey   \n",
      "97  0809e277-0af2-46df-b5ff-de10995b95d5               job_pkey   \n",
      "98  0809e277-0af2-46df-b5ff-de10995b95d5   job_run_details_pkey   \n",
      "99  0809e277-0af2-46df-b5ff-de10995b95d5  jobname_username_uniq   \n",
      "\n",
      "    index_rows_reads  index_rows_writes  index_scans  index_size  \\\n",
      "0                0.0                0.0          0.0      5672.0   \n",
      "1                0.0                0.0          0.0        16.0   \n",
      "2                0.0                0.0          0.0        16.0   \n",
      "3              100.0              100.0          1.0        32.0   \n",
      "4                0.0                0.0          0.0    554856.0   \n",
      "..               ...                ...          ...         ...   \n",
      "95         1219920.0                0.0        272.0      5808.0   \n",
      "96               0.0                0.0          0.0        16.0   \n",
      "97               0.0                0.0          0.0        16.0   \n",
      "98               0.0                0.0          0.0        72.0   \n",
      "99               0.0                0.0          0.0        16.0   \n",
      "\n",
      "    pages_read_from_buffer  pages_read_from_disk       table_name  \n",
      "0                      6.0                   3.0          account  \n",
      "1                      6.0                   4.0         accounts  \n",
      "2                      0.0                   2.0         aircraft  \n",
      "3                      2.0                   6.0          airport  \n",
      "4                  10470.0                  52.0    boarding_pass  \n",
      "..                     ...                   ...              ...  \n",
      "95                  1273.0                 840.0           flight  \n",
      "96                     0.0                   0.0      index_stats  \n",
      "97                     0.0                   0.0              job  \n",
      "98                     0.0                   0.0  job_run_details  \n",
      "99                     0.0                   0.0              job  \n",
      "\n",
      "[100 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*) FROM QUERY_DETAILS\n",
    "\"\"\"\n",
    "table = client.query(query=query, database=bucket, mode =\"all\", language=\"influxql\")\n",
    "dataframe = table.to_pandas() # This one automatically eliminitaes the NULL values. Not good. \n",
    "print (dataframe)\n",
    "\n",
    "## Some usefule commands ( https://docs.influxdata.com/influxdb/v1/query_language/explore-schema/)\n",
    "## SHOW RETENTION POLICIES;\n",
    "## SHOW MEASUREMENTS;\n",
    "## SELECT calls, host FROM QUERY_DETAILS LIMIT 10;  I think you must select at least one measure or it returns an empty results set\n",
    "## Notice - The SELECT should NOT contain the columns again (weird, I know). It shows the columns, includig time, automatically, based on your selection. \n",
    "query = \"\"\"\n",
    "SELECT mean(calls) \n",
    "FROM QUERY_DETAILS \n",
    "WHERE database_name = 'airbases'\n",
    "AND time >=  '2023-10-01 00:00:00'\n",
    "AND host = 'database-2.cofhrj7zmyn4.eu-central-1.rds.amazonaws.com'\n",
    "GROUP BY  query_id, time(60m);\n",
    "\"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM DS_INDEXES_ACTIVITY\n",
    "LIMIT 100;\n",
    "\"\"\"\n",
    "table = client.query(query=query, database=bucket, mode =\"all\", language=\"influxql\")\n",
    "dataframe = table.to_pandas() # This one automatically eliminitaes the NULL values. Not good. \n",
    "print (dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Data Frame with the dummy data. \n",
    "Step 1: A single Query ID, last 3 days, group hourly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Number of hosts, databases, and tables\n",
    "num_hosts = 1\n",
    "num_databases_per_host = 1\n",
    "num_tables_per_database = 200\n",
    "num_days = 3\n",
    "\n",
    "# Arrays of hosts and databases\n",
    "hosts = [f'host_{i}' for i in range(1, num_hosts + 1)]\n",
    "databases = [f'db_{i}' for i in range(1, num_databases_per_host * num_hosts + 1)]\n",
    "\n",
    "data = {'time': [], 'host_id': [], 'db_id': [], 'table_name': [], 'rows_read': [], 'rows_inserted': [],\n",
    "        'rows_deleted': [], 'rows_updated': []}\n",
    "\n",
    "# Iterate over hosts\n",
    "for host_id in hosts:\n",
    "    # Iterate over databases\n",
    "    for db_id in databases:\n",
    "        start_date = datetime(2023, 10, 1)\n",
    "\n",
    "        # Generate data for the DataFrame\n",
    "        for table_id in range(1, num_tables_per_database + 1):\n",
    "            for day in range(num_days):\n",
    "                for minute in range(0, 24 * 60, 5):\n",
    "                    timestamp = start_date + timedelta(days=day, minutes=minute)\n",
    "\n",
    "                    # Append data to the DataFrame\n",
    "                    data['time'].append(timestamp)\n",
    "                    data['host_id'].append(host_id)\n",
    "                    data['db_id'].append(db_id)\n",
    "                    data['table_name'].append(f'table_{table_id}')\n",
    "                    data['rows_read'].append(np.random.randint(0, 1000))\n",
    "                    data['rows_inserted'].append(np.random.randint(0, 500))\n",
    "                    data['rows_deleted'].append(np.random.randint(0, 200))\n",
    "                    data['rows_updated'].append(np.random.randint(0, 300))\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "df.to_csv('database_activity_data_last_3_days.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame: 172800\n",
      "DataFrame size (rows, columns): (172800, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in the DataFrame:\", len(df))\n",
    "print(\"DataFrame size (rows, columns):\", df.shape)\n",
    "# Save DataFrame to CSV file\n",
    "\n",
    " 172,800,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
